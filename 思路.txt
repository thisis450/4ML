在task1中，我们使用了独热编码来处理离散特征，独热编码是将离散特征的每个取值都看作一个新的特征，对于每个样本，
如果该样本在原始特征中的取值为该特征的某个取值，则在对应的特征下取值为1，其他特征下取值为0。
具体的在task1中，每个蛋白质被用96个20维的独热编码特征表示，其中96是蛋白质的长度，20是氨基酸的种类数。
对于task1使用独热编码的好处是，可以将离散特征的取值扩展到了欧式空间，使得特征之间的距离计算更加合理，
同时也在一定程度上解决了线性不可分的问题。但是独热编码也存在一些问题，比如当类别的数量很多时，独热编码会导致特征空间急剧膨胀，计算复杂度增加，同时也会引入一些噪声。
这也是我们在task2中要进行pca降维的原因。
在task2中我选用了不同的主成分数量进行PCA降维，然后图示（ppt第一页）这三张图分别是pca维度选择2,3,4时的结果，这三张图看起来并没有很好的根据主成分区分开功能性和非功能性，然后按照参考的代码中，同样的对不同维度的Explained Variance
进行输出，发现低维度的时候这个损失大的离谱，得到几百的时候才有比较可靠的效果。
然后接着在task3中我选择的是使用KMeans进行聚类，考虑在task2中得到的曲线，我在这里选择了使用PCA降到600维去进行对应的分类效果测试
我尝试了一些不同的聚类数量，并且把他在前三个主成分构成的三维空间中进行了可视化（600维难以可视化），这里以聚为2，3,4类为例（ppt第三页），看到似乎并没有一个特别好的区分效果。
对其中聚类为两类的，我尝试用一种方法量化他的准确性，我把他的分类映射到使得能让准确率最高的实际标签上，然后计算聚类结果的准确性，最终的结果为0.63，然后考虑到这里数据的标签比例大概是42/70，这个结果表面kmeans
在这里几乎没起到作用
同样的，用相同的方法，我把自然序列和人工序列统一到一起，然后设置他们的标签进行聚类，仍然也没有得到很好的分类结果。。。不过这很难说是生成的数据好还是此处kmeans的效果不佳，毕竟在对功能性的聚类分类上，
其几乎没起到区分作用
接下来的话就是task4中的分类器了，这里我选择搭建了一个全连接神经网络，他的结构比较简单，就是几层简单的全连接层，中间的激活函数为relu，然后加上了一些dropout层，最后输出用了sigmoid函数，这是为了让输出在0-1之间，表示
二分类的概率。
训练过程中的数据为了顺便验证前面几个task的效果，使用的是独热编码后进行pca降维的数据进行训练,pca维度我尝试了一些不同的维度，不过考虑到在task3中我们得到的Explained Variance，尝试的一些数据的pca维度比较大，
在ppt中展示的是维度选择40维和300维的结果，对于40维的pca在训练集上的准确率为97。54%，在测试集上的准确率为83.89,具体的混淆矩阵的TP,FP等数据可以看ppt上的图片，而对于300维的pca在训练集上的准确率为100%，
在测试集上的准确率为83.45%,看到在300维下，在训练集中能有100%的准确率，我意识到这里可能存在了过拟合的情况，所以我又尝试了减少了一些训练的轮次,但在训练集和测试集中的效果并没有变得更好，
然后也尝试了减少神经网络中全连接层的维度，不过并没有很好的改善效果，这可能需要设计更好的神经网络结构来解决。
然后根据在测试集中的准确率，我这里最终选择了40维在10000轮下的训练结果作为在task5中的分类器。

在task5中，我尝试了不同的生成数据的方法，一开始直接用一个lstm去生成数据，不过发现生成的效果并不是很好，所以改用了GAN，不过考虑到蛋白质序列应该是和上下文有关的，在生成器和判别器的组成上，仍然是使用了lstm，
输入一个序列（初始为种子），然后不断地根据前文生成下一个氨基酸，直到达到最大长度，判别器则是输入一个氨基酸序列，根据这个序列的特征来判断这个序列是真实的还是生成的，然后根据这个判断来更新生成器和判别器。
训练出来的结果看起来还是比较像一个蛋白质序列的（见文件generated.faa），将对应的生成序列输入到之前训练好的分类器中，一部分的生成序列被判别为功能性，一部分被判别为非功能性（这里我回来把非功能和功能的数据分开来，只用功能的数据训练
一下看看结果）